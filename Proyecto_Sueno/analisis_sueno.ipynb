{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a33e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "An√°lisis de Datos: Patrones de Sue√±o y Estilo de Vida\n",
    "Autor: Josu√© Miranda G.\n",
    "Descripci√≥n: EDA, limpieza, outliers (IQR), creaci√≥n de target binario,\n",
    "matriz de correlaci√≥n, divisi√≥n estratificada 80/20 y guardado de train/test.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ---------------------------\n",
    "# Configuraci√≥n\n",
    "# ---------------------------\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "np.random.seed(42)\n",
    "\n",
    "os.makedirs('imagenes', exist_ok=True)\n",
    "os.makedirs('datos', exist_ok=True)\n",
    "\n",
    "# ---------------------------\n",
    "# CARGA: ajustar nombre si lo descarga de Kaggle\n",
    "# ---------------------------\n",
    "# En Kaggle el archivo suele llamarse algo como:\n",
    "# \"Sleep_health_and_lifestyle_dataset.csv\" o \"sleep_data.csv\".\n",
    "# Descarga manual o usando kaggle-cli y pon el path correcto aqu√≠.\n",
    "csv_paths_to_try = [\n",
    "    'datos/sleep_data.csv',\n",
    "    'datos/Sleep_health_and_lifestyle_dataset.csv',\n",
    "    'sleep/Sleep_health_and_lifestyle_dataset.csv',\n",
    "    'Sleep_health_and_lifestyle_dataset.csv'\n",
    "]\n",
    "\n",
    "for p in csv_paths_to_try:\n",
    "    if os.path.exists(p):\n",
    "        df = pd.read_csv(p)\n",
    "        print(f\"üì• Cargado: {p}\")\n",
    "        break\n",
    "else:\n",
    "    raise FileNotFoundError(\n",
    "        \"No se encontr√≥ el CSV. Descargue el dataset de Kaggle y coloque el CSV en 'datos/'. \"\n",
    "        \"Nombre esperado: Sleep_health_and_lifestyle_dataset.csv o sleep_data.csv\"\n",
    "    )\n",
    "\n",
    "# ---------------------------\n",
    "# Exploraci√≥n inicial\n",
    "# ---------------------------\n",
    "print(\"\\nDimensiones:\", df.shape)\n",
    "display(df.head(5))\n",
    "print(\"\\nInfo de columnas:\")\n",
    "print(df.info())\n",
    "print(\"\\nResumen estad√≠stico (num√©ricas):\")\n",
    "display(df.describe(include=[np.number]).T)\n",
    "print(\"\\nValores nulos por columna:\")\n",
    "display(df.isnull().sum())\n",
    "\n",
    "# ---------------------------\n",
    "# Tratamiento de valores vac√≠os\n",
    "# Explicaci√≥n: rellenamos num√©ricos con mediana (robusto a outliers) y\n",
    "# categ√≥ricos con la moda.\n",
    "# ---------------------------\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "for col in numeric_cols:\n",
    "    nnull = df[col].isnull().sum()\n",
    "    if nnull:\n",
    "        df[col].fillna(df[col].median(), inplace=True)\n",
    "        print(f\"Rellenado num√©rico: {col} ({nnull} valores) -> mediana\")\n",
    "\n",
    "for col in cat_cols:\n",
    "    nnull = df[col].isnull().sum()\n",
    "    if nnull:\n",
    "        df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "        print(f\"Rellenado categ√≥rico: {col} ({nnull} valores) -> moda\")\n",
    "\n",
    "# Nota: si 'Sleep Disorder' usa NaN para \"No disorder\" muchos notebooks lo convierten a 'No Sleep Disorder'.\n",
    "if 'Sleep Disorder' in df.columns:\n",
    "    df['Sleep Disorder'] = df['Sleep Disorder'].fillna('No Sleep Disorder')\n",
    "\n",
    "# ---------------------------\n",
    "# An√°lisis univariante\n",
    "# - Distribuciones de num√©ricas\n",
    "# - Conteo de categ√≥ricas\n",
    "# Explicaci√≥n: ver sesgo, asimetr√≠a, concentraciones para decidir transformaciones.\n",
    "# ---------------------------\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "# Histogramas (solo hasta 12 variables para evitar saturaci√≥n)\n",
    "n_plot = min(len(num_cols), 12)\n",
    "fig, axes = plt.subplots((n_plot+2)//3, 3, figsize=(14, 4*((n_plot+2)//3)))\n",
    "axes = axes.ravel()\n",
    "for i, c in enumerate(num_cols[:n_plot]):\n",
    "    axes[i].hist(df[c].dropna(), bins=30, alpha=0.75, edgecolor='k')\n",
    "    axes[i].set_title(c)\n",
    "plt.tight_layout()\n",
    "plt.savefig('imagenes/distribuciones_numericas.png', dpi=200)\n",
    "plt.close()\n",
    "\n",
    "# Categ√≥ricas: top categories\n",
    "fig, axes = plt.subplots((min(len(cat_cols),6)+2)//3, 3, figsize=(14, 4*((min(len(cat_cols),6)+2)//3)))\n",
    "axes = axes.ravel()\n",
    "for i, c in enumerate(cat_cols[:6]):\n",
    "    df[c].value_counts().plot(kind='bar', ax=axes[i])\n",
    "    axes[i].set_title(c)\n",
    "    axes[i].tick_params(axis='x', rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('imagenes/distribuciones_categoricas.png', dpi=200)\n",
    "plt.close()\n",
    "\n",
    "# ---- Deducciones ejemplo para Stress_Level si existe\n",
    "if 'Stress Level' in df.columns or 'Stress_Level' in df.columns:\n",
    "    sc = 'Stress Level' if 'Stress Level' in df.columns else 'Stress_Level'\n",
    "    print(\"\\nAn√°lisis resumen de\", sc)\n",
    "    print(df[sc].describe())\n",
    "    print(\"Media: %.2f - Mediana: %.2f - Std: %.2f\" % (df[sc].mean(), df[sc].median(), df[sc].std()))\n",
    "\n",
    "# ---------------------------\n",
    "# Filtrado de outliers (IQR)\n",
    "# Explicaci√≥n: eliminamos valores extremos que pudieran distorsionar modelos.\n",
    "# Procedimiento: para cada variable num√©rica (excluimos la variable 'Stress' por ahora),\n",
    "# construimos una m√°scara que mantiene filas dentro de [Q1-1.5IQR, Q3+1.5IQR].\n",
    "# ENFOQUE: calculamos m√°scara combinada (AND) para evitar eliminar muchas filas sucesivamente.\n",
    "# ---------------------------\n",
    "stress_col = None\n",
    "if 'Stress Level' in df.columns:\n",
    "    stress_col = 'Stress Level'\n",
    "elif 'Stress_Level' in df.columns:\n",
    "    stress_col = 'Stress_Level'\n",
    "\n",
    "num_cols_for_outlier = [c for c in num_cols if c != stress_col]\n",
    "\n",
    "# construimos mascara que inicialmente es True\n",
    "mask = pd.Series(True, index=df.index)\n",
    "outlier_report = {}\n",
    "for c in num_cols_for_outlier:\n",
    "    Q1 = df[c].quantile(0.25)\n",
    "    Q3 = df[c].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lb = Q1 - 1.5*IQR\n",
    "    ub = Q3 + 1.5*IQR\n",
    "    mask_col = df[c].between(lb, ub)\n",
    "    removed = (~mask_col).sum()\n",
    "    outlier_report[c] = int(removed)\n",
    "    # aplicamos el filtro combin√°ndolo (se puede cambiar a OR si se desea menos agresivo)\n",
    "    mask &= mask_col\n",
    "\n",
    "print(\"\\nOutliers detectados por variable (contados):\")\n",
    "for k, v in outlier_report.items():\n",
    "    print(f\"  - {k}: {v}\")\n",
    "\n",
    "before = len(df)\n",
    "df = df[mask].copy()\n",
    "after = len(df)\n",
    "print(f\"\\nFilas eliminadas por IQR multivariante: {before - after}  (dataset: {after} filas)\")\n",
    "\n",
    "# Explicaci√≥n en l√≠nea:\n",
    "# Elegimos IQR multivariante (AND) para asegurar que fila con outlier en varias variables solo se quite una vez.\n",
    "# Alternativa menos agresiva: aplicar IQR por variable y eliminar solo si excede en N variables.\n",
    "\n",
    "# ---------------------------\n",
    "# Creaci√≥n de variable objetivo binaria\n",
    "# Seg√∫n tu especificaci√≥n:\n",
    "#   3-6 -> 'ESTRES_MODERADO'\n",
    "#   7+  -> 'ESTRESADO'\n",
    "# Decisi√≥n pr√°ctica (explicada): Si existen valores <3 (muy bajo estr√©s),\n",
    "# para mantener una variable estrictamente binaria y consistente con la regla,\n",
    "# vamos a **filtrar** y conservar solo filas con Stress >= 3.\n",
    "# Razonamiento: la regla que diste define categor√≠as a partir de 3. Mantener <3 introducir√≠a una categor√≠a\n",
    "# no contemplada por la regla binaria. Si prefieres otra opci√≥n (ej. agrupar <3 con 'ESTRES_MODERADO'),\n",
    "# puedo ajustar el c√≥digo.\n",
    "# ---------------------------\n",
    "if stress_col is None:\n",
    "    raise KeyError(\"No se encontr√≥ columna de nivel de estr√©s. Revisar nombre de columna (Stress Level o Stress_Level).\")\n",
    "\n",
    "# Convertir a num√©rico por si viene como object\n",
    "df[stress_col] = pd.to_numeric(df[stress_col], errors='coerce')\n",
    "initial_len = len(df)\n",
    "df = df[df[stress_col] >= 3].copy()\n",
    "filtered_len = len(df)\n",
    "print(f\"\\nFilas removidas por tener Stress < 3: {initial_len - filtered_len} (para crear target binaria seg√∫n regla)\")\n",
    "\n",
    "df['Stress_Category'] = df[stress_col].apply(lambda x: 'ESTRES_MODERADO' if 3 <= x <= 6 else 'ESTRESADO')\n",
    "\n",
    "print(\"\\nCuenta por categor√≠a:\")\n",
    "print(df['Stress_Category'].value_counts())\n",
    "print(\"\\nProporciones (%):\")\n",
    "print(df['Stress_Category'].value_counts(normalize=True) * 100)\n",
    "\n",
    "# Eliminar variable num√©rica original (especificaci√≥n del ejercicio)\n",
    "df.drop(columns=[stress_col], inplace=True)\n",
    "print(\"\\nVariable num√©rica de estr√©s eliminada del dataset (por petici√≥n).\")\n",
    "\n",
    "# ---------------------------\n",
    "# An√°lisis bivariante: target vs todas las variables\n",
    "# Guardamos boxplots para num√©ricas y barras/porcentajes para categ√≥ricas\n",
    "# ---------------------------\n",
    "num_after = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_after = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "if 'Stress_Category' in cat_after:\n",
    "    cat_after = [c for c in cat_after if c != 'Stress_Category']\n",
    "\n",
    "# Boxplots num√©ricas por categor√≠a\n",
    "n_plot = min(len(num_after), 12)\n",
    "if n_plot > 0:\n",
    "    fig, axes = plt.subplots((n_plot+2)//3, 3, figsize=(14, 4*((n_plot+2)//3)))\n",
    "    axes = axes.ravel()\n",
    "    for i, c in enumerate(num_after[:n_plot]):\n",
    "        sns.boxplot(x='Stress_Category', y=c, data=df, ax=axes[i])\n",
    "        axes[i].set_title(f'{c} vs Stress_Category')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('imagenes/bivariante_numericas.png', dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "# Para categ√≥ricas: proporciones dentro de cada Stress_Category\n",
    "for c in cat_after[:6]:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    ct = pd.crosstab(df[c], df['Stress_Category'], normalize='index') * 100\n",
    "    ct.plot(kind='bar', stacked=False)\n",
    "    plt.title(f'{c} por Stress_Category (% por fila)')\n",
    "    plt.ylabel('% por categor√≠a de \"{0}\"'.format(c))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'imagenes/bivariante_{c}.png', dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "# ---------------------------\n",
    "# Matriz de correlaci√≥n (codificamos target)\n",
    "# ---------------------------\n",
    "df['Stress_Encoded'] = df['Stress_Category'].map({'ESTRES_MODERADO':0, 'ESTRESADO':1})\n",
    "corr_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "corr = df[corr_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(corr, annot=True, fmt='.2f', cmap='coolwarm', center=0)\n",
    "plt.title('Matriz de correlaci√≥n (num√©ricas)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('imagenes/matriz_correlacion.png', dpi=200)\n",
    "plt.close()\n",
    "\n",
    "# Reporte correlaciones altas\n",
    "high_corr_pairs = []\n",
    "for i in range(len(corr.columns)):\n",
    "    for j in range(i+1, len(corr.columns)):\n",
    "        val = corr.iloc[i,j]\n",
    "        if abs(val) > 0.7:\n",
    "            high_corr_pairs.append((corr.columns[i], corr.columns[j], val))\n",
    "if high_corr_pairs:\n",
    "    print(\"\\nCorrelaciones fuertes (|r|>0.7):\")\n",
    "    for a,b,v in high_corr_pairs:\n",
    "        print(f\"  - {a} <-> {b}: {v:.2f}\")\n",
    "else:\n",
    "    print(\"\\nNo se detectaron correlaciones muy fuertes (|r|>0.7).\")\n",
    "\n",
    "# Si hay variables muy correlacionadas entre s√≠ (no objetivo), recomendar eliminar la que \"tenga menos sentido\"\n",
    "# Ejemplo comentado:\n",
    "# if 'Cost_of_Living' and 'Salary' correlacionan fuertemente, podr√≠amos eliminar 'Cost_of_Living' si consideramos 'Salary' m√°s relevante.\n",
    "\n",
    "# ---------------------------\n",
    "# Divisi√≥n Train/Test 80/20 estratificada\n",
    "# ---------------------------\n",
    "X = df.drop(columns=['Stress_Category', 'Stress_Encoded'])\n",
    "y = df['Stress_Category']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain: {len(X_train)} | Test: {len(X_test)}\")\n",
    "print(\"\\nProporciones en Train (%):\")\n",
    "print(y_train.value_counts(normalize=True) * 100)\n",
    "print(\"\\nProporciones en Test (%):\")\n",
    "print(y_test.value_counts(normalize=True) * 100)\n",
    "\n",
    "train_df = pd.concat([X_train, y_train.reset_index(drop=True)], axis=1)\n",
    "test_df = pd.concat([X_test, y_test.reset_index(drop=True)], axis=1)\n",
    "train_df.to_csv('datos/train.csv', index=False)\n",
    "test_df.to_csv('datos/test.csv', index=False)\n",
    "print(\"\\nGuardados: datos/train.csv, datos/test.csv\")\n",
    "\n",
    "# Guardado final del dataset procesado (por si se requiere)\n",
    "df.to_csv('datos/processed_full.csv', index=False)\n",
    "print(\"Guardado: datos/processed_full.csv\")\n",
    "\n",
    "print(\"\\n‚úÖ EDA completado. Revise la carpeta 'imagenes/' para gr√°ficas y 'datos/' para CSVs.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
