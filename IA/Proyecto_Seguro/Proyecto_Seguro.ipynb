{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA Seguro Médico\n",
    "\n",
    "Notebook de análisis exploratorio de datos (EDA) sobre el dataset de costos de seguros médicos.\n",
    "Inspirado en el formato y explicaciones de Proyecto_Sueno."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carga de librerías y datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "DATA_DIR = 'data'\n",
    "OUTPUT_DIR = 'output'\n",
    "FIGS_DIR = os.path.join(OUTPUT_DIR, 'figs')\n",
    "os.makedirs(FIGS_DIR, exist_ok=True)\n",
    "\n",
    "# Carga de datos\n",
    "df = pd.read_csv(os.path.join(DATA_DIR, 'insurance.csv'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Análisis inicial y descripción del conjunto de datos\n",
    "- Revisamos tipos de variables\n",
    "- Exploramos datos faltantes\n",
    "- Describimos numéricas\n",
    "- Justificamos cada paso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Justificación**: Revisar tipos y valores faltantes asegura que el análisis sea confiable y permite decidir si se requiere imputación o limpieza adicional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Transformaciones iniciales\n",
    "- Convertimos columnas categóricas a tipo 'category'.\n",
    "- Aclaramos por qué lo hacemos: facilita visualizaciones y tratamiento posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['sex', 'smoker', 'region']\n",
    "for c in cat_cols:\n",
    "    df[c] = df[c].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Análisis univariante\n",
    "- Revisamos distribuciones de numéricas y categóricas individualmente.\n",
    "- Incluimos deducciones tipo: \"Observamos que la mayoría de los pacientes no son fumadores, pero los fumadores tienen costos mucho más altos\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables numéricas\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "for col in num_cols:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.histplot(df[col], kde=True)\n",
    "    plt.title(f'Distribución de {col}')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(FIGS_DIR, f'univariate_{col}.png'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables categóricas + children (discreta)\n",
    "for col in cat_cols + ['children']:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.countplot(data=df, x=col)\n",
    "    plt.title(f'Conteo por {col}')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(FIGS_DIR, f'univariate_{col}.png'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deducciones univariantes\n",
    "- Escribe aquí tus observaciones sobre cada variable, por ejemplo:\n",
    "  - La variable `smoker` tiene una minoría de casos positivos, pero es crucial analizar su impacto en el costo.\n",
    "  - El costo (`charges`) está sesgado a la derecha, sugiriendo algunos pacientes con costos extremadamente altos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Filtrado de outliers\n",
    "- Aplicamos método IQR sobre `charges` para quitar extremos y facilitar el análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers_iqr(df_in, col, k=1.5):\n",
    "    q1 = df_in[col].quantile(0.25)\n",
    "    q3 = df_in[col].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower = q1 - k * iqr\n",
    "    upper = q3 + k * iqr\n",
    "    mask = (df_in[col] >= lower) & (df_in[col] <= upper)\n",
    "    return df_in.loc[mask]\n",
    "\n",
    "df_filtered = remove_outliers_iqr(df, 'charges', k=1.5)\n",
    "df_filtered.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Justificación**: El corte por IQR permite trabajar con datos más representativos y menos sesgados por casos extremos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Tratamiento de la variable objetivo\n",
    "- Decidimos si transformar `charges` (log) o dejarla como está."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (df_filtered['charges'] <= 0).any():\n",
    "    print('Advertencia: charges tiene valores no positivos; no se puede aplicar log sin ajuste')\n",
    "else:\n",
    "    df_filtered['log_charges'] = np.log(df_filtered['charges'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Justificación**: El log ayuda a normalizar la variable objetivo si queremos modelos lineales o entender mejor la dispersión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Análisis bivariante\n",
    "- Relación entre `charges` y cada variable (gráficas y deducciones)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter para numéricas vs charges\n",
    "for col in num_cols:\n",
    "    if col == 'charges' or col == 'log_charges':\n",
    "        continue\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.scatterplot(data=df_filtered, x=col, y='charges', alpha=0.6)\n",
    "    plt.title(f'Charges vs {col}')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(FIGS_DIR, f'bivariate_charges_vs_{col}.png'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot para categóricas vs charges\n",
    "for col in cat_cols + ['children']:\n",
    "    plt.figure(figsize=(8,5))\n",
    "    sns.boxplot(data=df_filtered, x=col, y='charges')\n",
    "    plt.title(f'Charges por {col}')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(FIGS_DIR, f'bivariate_charges_by_{col}.png'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Matriz de correlación y filtrado de variables redundantes\n",
    "- Mostramos correlaciones con `charges`.\n",
    "- Eliminamos variables redundantes si corresponde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df_filtered.select_dtypes(include=[np.number]).corr()\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(corr, annot=True, fmt='.2f', cmap='coolwarm', square=True)\n",
    "plt.title('Matriz de correlación (numéricas)')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIGS_DIR, 'correlation_matrix.png'))\n",
    "plt.show()\n",
    "corr['charges'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. División de dataset en `train.csv` y `test.csv` (80/20, estratificado)\n",
    "- Estratificamos por bins de `charges` para mantener la proporción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins = 5\n",
    "df_filtered['charges_bin'] = pd.qcut(df_filtered['charges'], q=n_bins, labels=False, duplicates='drop')\n",
    "train_df, test_df = train_test_split(df_filtered, test_size=0.2, random_state=42, stratify=df_filtered['charges_bin'])\n",
    "prop_train = train_df['charges_bin'].value_counts(normalize=True).sort_index()\n",
    "prop_test = test_df['charges_bin'].value_counts(normalize=True).sort_index()\n",
    "print('Proporciones por bin en train:', prop_train)\n",
    "print('Proporciones por bin en test:', prop_test)\n",
    "train_df = train_df.drop(columns=['charges_bin'])\n",
    "test_df = test_df.drop(columns=['charges_bin'])\n",
    "train_df.to_csv(os.path.join(DATA_DIR, 'train.csv'), index=False)\n",
    "test_df.to_csv(os.path.join(DATA_DIR, 'test.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Justificación**: Estratificar los splits hace que los modelos se evalúen en test sobre la misma distribución que el train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Guardado y resumen final\n",
    "- Guardamos deducciones, correlaciones y resumen en archivos de texto.\n",
    "- Explicamos cómo usar los resultados para modelado futuro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "with open(os.path.join(OUTPUT_DIR, 'deductions.txt'), 'w', encoding='utf-8') as f:\n",
    "    f.write('Deducciones:\\n')\n",
    "    f.write('- charges es la variable objetivo.\\n')\n",
    "    f.write('- Fumar y BMI tienen alto impacto en el costo.\\n')\n",
    "    f.write('- Los outliers en charges pueden distorsionar los resultados.\\n')\n",
    "    f.write('- Las proporciones train/test se mantienen por bins.\\n')\n",
    "\n",
    "with open(os.path.join(OUTPUT_DIR, 'correlations_with_target.txt'), 'w', encoding='utf-8') as f:\n",
    "    corr_target = corr['charges'].sort_values(ascending=False)\n",
    "    f.write(corr_target.to_string())\n",
    "\n",
    "with open(os.path.join(OUTPUT_DIR, 'summary.txt'), 'w', encoding='utf-8') as f:\n",
    "    f.write(f'Shape original: {df.shape}\\n')\n",
    "    f.write(f'Shape después filtro IQR: {df_filtered.shape}\\n')\n",
    "    f.write(f'Train shape: {train_df.shape}\\n')\n",
    "    f.write(f'Test shape: {test_df.shape}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Siguientes pasos\n",
    "- Puedes usar los archivos generados para construir modelos predictivos (regresión, clasificación, etc).\n",
    "- Revisa `output/figs/` para las visualizaciones.\n",
    "- Los splits están listos para entrenar y validar modelos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
